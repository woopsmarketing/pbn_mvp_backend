"""
Celery ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë° êµ¬ì„±
- Redisë¥¼ ë¸Œë¡œì»¤ ë° ê²°ê³¼ ë°±ì—”ë“œë¡œ ì‚¬ìš©
- Windows í™˜ê²½ì„ ìœ„í•œ ì„¤ì • í¬í•¨
- ì‘ì—… ê²°ê³¼ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •
- v1.3 - ë¡œê·¸ ê°€ë…ì„± ê°œì„  (2025.01.25)
"""

import os
import sys
from celery import Celery
from celery.schedules import crontab
from dotenv import load_dotenv
from kombu import Exchange, Queue

# Celery ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
celery = Celery("backlinkvending")

# v1.1 - Celery ì›Œì»¤ Task ëª¨ë“ˆ ëª…ì‹œì  import (2025.07.15)
from app.core.config import settings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Redis ì„¤ì • - ë¸Œë¡œì»¤ì™€ ê²°ê³¼ ë°±ì—”ë“œ ë¶„ë¦¬
broker_url = settings.CELERY_BROKER_URL or "redis://localhost:6379/0"
result_backend_url = settings.CELERY_RESULT_BACKEND or "redis://localhost:6379/1"

print(f"ğŸ”— [Celery ì„¤ì •] ë¸Œë¡œì»¤ URL: {broker_url}")
print(f"ğŸ“Š [Celery ì„¤ì •] ê²°ê³¼ ë°±ì—”ë“œ URL: {result_backend_url}")

# Celery êµ¬ì„±
celery.conf.update(
    # ë¸Œë¡œì»¤ ì„¤ì •
    broker_url=broker_url,
    result_backend=result_backend_url,
    # í´ë¼ìš°ë“œ í™˜ê²½ ìµœì í™”: ì—°ê²° ì„¤ì •
    broker_connection_retry_on_startup=True,
    broker_connection_retry=True,
    broker_connection_max_retries=10,
    broker_heartbeat=30,
    broker_pool_limit=10,
    # Redis ì—°ê²° íƒ€ì„ì•„ì›ƒ ì„¤ì •
    redis_socket_timeout=30.0,
    redis_socket_connect_timeout=30.0,
    redis_retry_on_timeout=True,
    redis_health_check_interval=10,
    # ì§ë ¬í™” ì„¤ì •
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Seoul",
    enable_utc=True,
    # ì‘ì—… ê²°ê³¼ ì„¤ì •
    result_expires=3600,
    task_track_started=True,
    task_result_extended=True,
    result_extended=True,
    # í´ë¼ìš°ë“œ í™˜ê²½ ìµœì í™”: Worker ì„¤ì •
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    worker_max_tasks_per_child=50,
    worker_max_memory_per_child=200000,
    worker_disable_rate_limits=True,
    # ë¡œê¹… ì„¤ì • (ê°„ì†Œí™”ëœ í¬ë§·)
    worker_log_format="[%(levelname)s] %(message)s",
    worker_task_log_format="[TASK] %(task_name)s - %(message)s",
    worker_send_task_events=True,
    task_send_sent_event=True,
    # ë³´ì•ˆ ì„¤ì •
    worker_hijack_root_logger=False,
    worker_redirect_stdouts=False,
    # ë¼ìš°íŒ… ì„¤ì •
    task_routes={
        "app.tasks.email_tasks.*": {"queue": "email"},
        "app.tasks.pbn_tasks.*": {"queue": "pbn"},
        "app.tasks.pbn_rest_tasks.*": {"queue": "pbn"},
        "app.tasks.report_tasks.*": {"queue": "reports"},
        "*": {"queue": "default"},
    },
    # í ì„¤ì •
    task_default_queue="default",
    task_queues=(
        Queue("default", Exchange("default"), routing_key="default"),
        Queue("email", Exchange("email"), routing_key="email"),
        Queue("pbn", Exchange("pbn"), routing_key="pbn"),
        Queue("reports", Exchange("reports"), routing_key="reports"),
    ),
    # ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • (Beat)
    beat_schedule={
        "daily-report": {
            "task": "app.tasks.report_tasks.generate_daily_report",
            "schedule": crontab(hour=9, minute=0),
        },
        "cleanup-old-logs": {
            "task": "app.tasks.scheduled_tasks.cleanup_old_email_logs",
            "schedule": crontab(hour=2, minute=0),
        },
        "check-pbn-status": {
            "task": "app.tasks.scheduled_tasks.check_pbn_site_status",
            "schedule": crontab(minute="*/30"),
        },
    },
    # ì—ëŸ¬ ì²˜ë¦¬ ì„¤ì •
    task_reject_on_worker_lost=True,
    task_ignore_result=False,
)


# ë””ë²„ê·¸ íƒœìŠ¤í¬
@celery.task
def debug_task():
    """Celery ì—°ê²° í…ŒìŠ¤íŠ¸ìš© ë””ë²„ê·¸ íƒœìŠ¤í¬"""
    print("ğŸ” [DEBUG] Celery íƒœìŠ¤í¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    return "debug_task_completed"


# Health check íƒœìŠ¤í¬
@celery.task
def system_health_check():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ íƒœìŠ¤í¬"""
    return {"status": "healthy", "message": "Celery worker is running"}


# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬
from celery.signals import (
    task_prerun,
    task_postrun,
    task_failure,
    worker_ready,
    worker_shutdown,
)


@task_prerun.connect
def task_prerun_handler(
    sender=None, task_id=None, task=None, args=None, kwargs=None, **kwds
):
    """íƒœìŠ¤í¬ ì‹¤í–‰ ì „ ë¡œê¹…"""
    task_name = task.name.split(".")[-1] if task else "unknown"
    print(f"â–¶ï¸  [TASK] {task_name} ì‹œì‘")


@task_postrun.connect
def task_postrun_handler(
    sender=None,
    task_id=None,
    task=None,
    args=None,
    kwargs=None,
    retval=None,
    state=None,
    **kwds,
):
    """íƒœìŠ¤í¬ ì‹¤í–‰ í›„ ë¡œê¹…"""
    task_name = task.name.split(".")[-1] if task else "unknown"
    if state == "SUCCESS":
        print(f"âœ… [TASK] {task_name} ì™„ë£Œ")
    else:
        print(f"âš ï¸  [TASK] {task_name} ìƒíƒœ: {state}")


@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, einfo=None, **kwds):
    """íƒœìŠ¤í¬ ì‹¤íŒ¨ ì‹œ ë¡œê¹…"""
    task_name = sender.name.split(".")[-1] if sender else "unknown"
    print(f"âŒ [TASK] {task_name} ì‹¤íŒ¨: {exception}")


@worker_ready.connect
def worker_ready_handler(sender=None, **kwargs):
    """Workerê°€ ì¤€ë¹„ë˜ì—ˆì„ ë•Œ"""
    print("ğŸ‰ [WORKER] ì¤€ë¹„ ì™„ë£Œ - íƒœìŠ¤í¬ ìˆ˜ì‹  ê°€ëŠ¥!")
    print(f"   â””â”€ Worker: {sender.hostname}")


@worker_shutdown.connect
def worker_shutdown_handler(sender=None, **kwargs):
    """Workerê°€ ì¢…ë£Œë  ë•Œ"""
    print("ğŸ‘‹ [WORKER] ì¢…ë£Œë¨")


# ê°„ì†Œí™”ëœ ì‹œì‘ ë¡œê·¸
print("ğŸš€ [CELERY] BacklinkVending Worker ì´ˆê¸°í™” ì™„ë£Œ")
print(f"   â””â”€ ë¸Œë¡œì»¤: {broker_url.split('@')[-1] if '@' in broker_url else broker_url}")
print(f"   â””â”€ í: default, email, pbn, reports")

# íƒœìŠ¤í¬ ëª¨ë“ˆ ìë™ ê²€ìƒ‰
try:
    celery.autodiscover_tasks(
        [
            "app.tasks.email_tasks",
            "app.tasks.pbn_rest_tasks",
            "app.tasks.pbn_tasks",
            "app.tasks.report_tasks",
            "app.tasks.scheduled_tasks",
        ]
    )
    print("âœ… [CELERY] íƒœìŠ¤í¬ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âš ï¸  [CELERY] íƒœìŠ¤í¬ ëª¨ë“ˆ ë¡œë“œ ì˜¤ë¥˜: {e}")

print("â³ [CELERY] Worker ì‹œì‘ ëŒ€ê¸° ì¤‘...")
