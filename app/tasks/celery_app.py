"""
Celery ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì • ë° êµ¬ì„±
- Redisë¥¼ ë¸Œë¡œì»¤ ë° ê²°ê³¼ ë°±ì—”ë“œë¡œ ì‚¬ìš©
- Windows í™˜ê²½ì„ ìœ„í•œ ì„¤ì • í¬í•¨
- ì‘ì—… ê²°ê³¼ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •
- v1.3 - ì‘ì—… ê²°ê³¼ ì¶”ì  ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™” (2025.01.08)
"""

import os
import sys
from celery import Celery
from celery.schedules import crontab
from dotenv import load_dotenv
from kombu import Exchange, Queue

# Celery ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (celery_worker.pyì™€ ë™ì¼í•œ ì´ë¦„ ì‚¬ìš©)
celery = Celery("backlinkvending")

# v1.1 - Celery ì›Œì»¤ Task ëª¨ë“ˆ ëª…ì‹œì  import (2025.07.15)
# celery ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì´í›„ì—ë§Œ import (ìˆœí™˜ ì°¸ì¡° ë°©ì§€)
from app.core.config import settings

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Windows í™˜ê²½ì—ì„œ pickle ì§ë ¬í™” ë¬¸ì œ í•´ê²°
if sys.platform == "win32":
    os.environ.setdefault("FORKED_BY_MULTIPROCESSING", "1")

# Redis ì„¤ì • - ë¸Œë¡œì»¤ì™€ ê²°ê³¼ ë°±ì—”ë“œ ë¶„ë¦¬
broker_url = settings.CELERY_BROKER_URL or "redis://localhost:6379/0"
result_backend_url = settings.CELERY_RESULT_BACKEND or "redis://localhost:6379/1"

print(f"ğŸ”— [Celery ì„¤ì •] ë¸Œë¡œì»¤ URL: {broker_url}")
print(f"ğŸ“Š [Celery ì„¤ì •] ê²°ê³¼ ë°±ì—”ë“œ URL: {result_backend_url}")

# Celery êµ¬ì„±
celery.conf.update(
    # ë¸Œë¡œì»¤ ì„¤ì • (ì˜¬ë°”ë¥¸ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    broker_url=broker_url,
    result_backend=result_backend_url,  # ë³„ë„ì˜ ê²°ê³¼ ë°±ì—”ë“œ ì‚¬ìš©
    # ì§ë ¬í™” ì„¤ì •
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Seoul",
    enable_utc=True,
    # ì‘ì—… ê²°ê³¼ ì„¤ì •
    result_expires=3600,  # 1ì‹œê°„ í›„ ê²°ê³¼ ë§Œë£Œ
    task_track_started=True,
    task_result_extended=True,
    result_extended=True,
    # ì‘ì—…ì(Worker) ì„¤ì •
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    worker_max_tasks_per_child=50,
    # ë¼ìš°íŒ… ì„¤ì •
    task_routes={
        # ì´ë©”ì¼ ê´€ë ¨ íƒœìŠ¤í¬
        "app.tasks.email_tasks.*": {"queue": "email"},
        # PBN ê´€ë ¨ íƒœìŠ¤í¬
        "app.tasks.pbn_tasks.*": {"queue": "pbn"},
        # ë³´ê³ ì„œ ê´€ë ¨ íƒœìŠ¤í¬
        "app.tasks.report_tasks.*": {"queue": "reports"},
        # ê¸°ë³¸ íƒœìŠ¤í¬
        "*": {"queue": "default"},
    },
    # í ì„¤ì •
    task_default_queue="default",
    task_queues=(
        Queue("default", Exchange("default"), routing_key="default"),
        Queue("email", Exchange("email"), routing_key="email"),
        Queue("pbn", Exchange("pbn"), routing_key="pbn"),
        Queue("reports", Exchange("reports"), routing_key="reports"),
    ),
    # ìŠ¤ì¼€ì¤„ ì‘ì—… ì„¤ì • (Beat)
    beat_schedule={
        "daily-report": {
            "task": "app.tasks.report_tasks.generate_daily_report",
            "schedule": crontab(hour=9, minute=0),  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
        },
        "cleanup-old-logs": {
            "task": "app.tasks.scheduled_tasks.cleanup_old_email_logs",
            "schedule": crontab(hour=2, minute=0),  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
        },
        "check-pbn-status": {
            "task": "app.tasks.scheduled_tasks.check_pbn_site_status",
            "schedule": crontab(minute="*/30"),  # 30ë¶„ë§ˆë‹¤
        },
    },
    # ì—ëŸ¬ ì²˜ë¦¬ ì„¤ì •
    task_reject_on_worker_lost=True,
    task_ignore_result=False,
    # ë¡œê¹… ì„¤ì • (ë” ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥)
    worker_log_format="[%(asctime)s: %(levelname)s/%(processName)s] %(message)s",
    worker_task_log_format="[%(asctime)s: %(levelname)s/%(processName)s][%(task_name)s(%(task_id)s)] %(message)s",
    worker_send_task_events=True,  # íƒœìŠ¤í¬ ì´ë²¤íŠ¸ ì „ì†¡ í™œì„±í™”
    task_send_sent_event=True,  # íƒœìŠ¤í¬ ì „ì†¡ ì´ë²¤íŠ¸ í™œì„±í™”
    # ë³´ì•ˆ ì„¤ì •
    worker_hijack_root_logger=False,
    worker_redirect_stdouts=True,  # stdoutì„ ë¡œê·¸ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
)

# v1.2 - Task ìë™ ê²€ìƒ‰ ì„¤ì • (2025.07.16)
celery.autodiscover_tasks(
    [
        "app.tasks.email_tasks",
        "app.tasks.pbn_tasks",
        "app.tasks.report_tasks",
        "app.tasks.scheduled_tasks",
        "app.tasks.pbn_rest_tasks",
    ]
)


# v1.3 - Celery ìƒíƒœ ëª¨ë‹ˆí„°ë§ (2025.01.08)
@celery.task(bind=True)
def debug_task(self):
    """ë””ë²„ê·¸ìš© íƒœìŠ¤í¬"""
    print(f"Request: {self.request!r}")
    return f"Task executed successfully: {self.request.id}"


# v1.3 - ì—ëŸ¬ í•¸ë“¤ëŸ¬ (2025.01.08)
@celery.task(bind=True)
def error_handler(self, uuid, err, traceback):
    """ì—ëŸ¬ ì²˜ë¦¬ íƒœìŠ¤í¬"""
    print(f"Task {uuid} raised exception: {err}\n{traceback}")


# ì»¨í…Œì´ë„ˆ í™˜ê²½ì—ì„œì˜ Celery ì—°ê²° í…ŒìŠ¤íŠ¸
@celery.task
def health_check():
    """Celery ìƒíƒœ í™•ì¸ìš© íƒœìŠ¤í¬"""
    return {
        "status": "healthy",
        "message": "BacklinkVending Celery worker is running",
        "timestamp": str(os.environ.get("CURRENT_TIME", "unknown")),
    }


# v1.3 - Celery ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ (2025.01.08)
from celery.signals import task_prerun, task_postrun, task_failure


@task_prerun.connect
def task_prerun_handler(
    sender=None, task_id=None, task=None, args=None, kwargs=None, **kwds
):
    """íƒœìŠ¤í¬ ì‹¤í–‰ ì „ ë¡œê¹…"""
    print(f"Task {task_id} started: {task.name}")


@task_postrun.connect
def task_postrun_handler(
    sender=None,
    task_id=None,
    task=None,
    args=None,
    kwargs=None,
    retval=None,
    state=None,
    **kwds,
):
    """íƒœìŠ¤í¬ ì‹¤í–‰ í›„ ë¡œê¹…"""
    print(f"Task {task_id} finished: {task.name} - State: {state}")


@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, einfo=None, **kwds):
    """íƒœìŠ¤í¬ ì‹¤íŒ¨ ì‹œ ë¡œê¹…"""
    print(f"Task {task_id} failed: {exception}")


# Celery ì›Œì»¤ ì‹œì‘ ì‹œ ë¡œê·¸
print("BacklinkVending Celery application configured successfully")
print(f"Broker URL: {broker_url}")
print(f"Worker queues: default, email, pbn, reports")
